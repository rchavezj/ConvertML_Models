{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import build_super_images\n",
    "from miscc.losses import sent_loss, words_loss\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "\n",
    "from datasets import TextDataset\n",
    "from datasets import prepare_data\n",
    "\n",
    "from model import RNN_ENCODER, CNN_ENCODER\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.TEXT.EMBEDDING_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    # build model ############################################################\n",
    "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "    cfg.TREE.BASE_SIZE = torch.FloatTensor(299)\n",
    "#     image_encoder = CNN_ENCODER(cfg.TREE.BASE_SIZE) #299 inside CNN_Encoder\n",
    "    labels = torch.LongTensor(range(batch_size))\n",
    "    start_epoch = 0\n",
    "    if cfg.TRAIN.NET_E != '':\n",
    "        state_dict = torch.load(cfg.TRAIN.NET_E)\n",
    "        text_encoder.load_state_dict(state_dict)\n",
    "        print('Load ', cfg.TRAIN.NET_E)\n",
    "        #\n",
    "        name = cfg.TRAIN.NET_E.replace('text_encoder')\n",
    "        state_dict = torch.load(name)\n",
    "#         image_encoder.load_state_dict(state_dict)\n",
    "        print('Load ', name)\n",
    "\n",
    "        istart = cfg.TRAIN.NET_E.rfind('_') + 8\n",
    "        iend = cfg.TRAIN.NET_E.rfind('.')\n",
    "        start_epoch = cfg.TRAIN.NET_E[istart:iend]\n",
    "        start_epoch = int(start_epoch) + 1\n",
    "        print('start_epoch', start_epoch)\n",
    "    if cfg.CUDA:\n",
    "        text_encoder = text_encoder\n",
    "#         image_encoder = image_encoder\n",
    "        labels = labels\n",
    "\n",
    "    return text_encoder, labels, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.TEXT.EMBEDDING_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'DAMSM',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': '../data/coco',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 128,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 0,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 5, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 15},\n",
      " 'TRAIN': {'BATCH_SIZE': 48,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.002,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'NET_E': '',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 5},\n",
      " 'TREE': {'BASE_SIZE': 299, 'BRANCH_NUM': 1},\n",
      " 'WORKERS': 1}\n"
     ]
    }
   ],
   "source": [
    "#Configurations\n",
    "cfg_from_file(\"cfg/DAMSM/coco.yml\")\n",
    "import pprint\n",
    "pprint.pprint(cfg)\n",
    "random.seed(random.randint(1, 10000))\n",
    "np.random.seed(random.randint(1, 10000))\n",
    "torch.manual_seed(random.randint(1, 10000))\n",
    "if cfg.CUDA:\n",
    "    torch.cuda.manual_seed_all(random.randint(1, 10000))\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = '../output/%s_%s_%s' % \\\n",
    "    (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
    "\n",
    "model_dir = os.path.join(output_dir, 'Model')\n",
    "image_dir = os.path.join(output_dir, 'Image')\n",
    "mkdir_p(model_dir)\n",
    "mkdir_p(image_dir)\n",
    "# Debug\n",
    "torch.cuda.device(cfg.GPU_ID)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load filenames from: ../data/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco/test/filenames.pickle (40470)\n",
      "Load from:  ../data/coco/captions.pickle\n",
      "=====================================================\n",
      "cfg.DATA_DIR:  ../data/coco\n",
      "cfg.TREE.BASE_SIZE:  299\n",
      "image_transform:  <torchvision.transforms.Compose object at 0x1c1eb064a8>\n",
      "cfg.TEXT.EMBEDDING_DIM 256\n",
      "=====================================================\n",
      "dataset.n_words: 27297  dataset.embeddings_num:  5\n",
      "Load filenames from: ../data/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco/test/filenames.pickle (40470)\n",
      "Load from:  ../data/coco/captions.pickle\n"
     ]
    }
   ],
   "source": [
    "# cfg.TREE.BASE_SIZE = 299\n",
    "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM-1))\n",
    "batch_size = cfg.TRAIN.BATCH_SIZE\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "dataset = TextDataset(\"../data/coco\", 'train',\n",
    "                      base_size=299,\n",
    "                      transform=image_transform)\n",
    "print(\"=====================================================\")\n",
    "print(\"cfg.DATA_DIR: \", cfg.DATA_DIR)\n",
    "print(\"cfg.TREE.BASE_SIZE: \", cfg.TREE.BASE_SIZE)\n",
    "print(\"image_transform: \", image_transform)\n",
    "print(\"cfg.TEXT.EMBEDDING_DIM\", cfg.TEXT.EMBEDDING_DIM)\n",
    "print(\"=====================================================\")\n",
    "print(\"dataset.n_words:\", dataset.n_words, \" dataset.embeddings_num: \", dataset.embeddings_num)\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "\n",
    "# # validation data #\n",
    "dataset_val = TextDataset(\"../data/coco\", 'test',\n",
    "                          base_size=cfg.TREE.BASE_SIZE,\n",
    "                          transform=image_transform)\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load filenames from: ../data/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco/test/filenames.pickle (40470)\n",
      "Load from:  ../data/coco/captions.pickle\n"
     ]
    }
   ],
   "source": [
    "split_dir, bshuffle = 'train', True\n",
    "if not cfg.TRAIN.FLAG:\n",
    "    # bshuffle = False\n",
    "    split_dir = 'test'\n",
    "dataset = TextDataset(cfg.DATA_DIR, 'train',base_size=cfg.TREE.BASE_SIZE,transform=image_transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.BATCH_SIZE,drop_last=True, shuffle=bshuffle, num_workers=int(cfg.WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.TextDataset at 0x1c2147cac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "text_encoder, labels, start_epoch = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_ENCODER(\n",
       "  (encoder): Embedding(27297, 300)\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (rnn): LSTM(300, 128, batch_first=True, dropout=0.5, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder.train()\n",
    "text_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 \n",
      "cap_lens\n",
      " tensor([ 15,  15,  15,  15,  14,  14,  14,  13,  13,  13,  12,  11,\n",
      "         11,  11,  11,  11,  11,  10,  10,  10,  10,  10,  10,  10,\n",
      "         10,  10,  10,  10,  10,  10,   9,   9,   9,   9,   9,   9,\n",
      "          9,   9,   9,   8,   8,   8,   8,   8,   8,   8,   8,   8]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(dataloader, 0):\n",
    "    imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
    "    hidden = text_encoder.init_hidden(batch_size)\n",
    "    print(\"step\", step, \"\\ncap_lens\\n\", cap_lens, \"\\n\") \n",
    "    if step == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "torch.Size([48, 15])\n",
      "tensor([[ 23046,  15790,   4114,   1943,  23046,   2861,  20752,  26444,\n",
      "          13598,   7515,  23046,   7510,  13540,   1943,  10402],\n",
      "        [ 23046,   8494,  26444,  16860,  11824,  10409,  23484,  23046,\n",
      "          15298,  15788,  10400,   1327,  14435,  23046,  14018],\n",
      "        [ 23046,  18903,  25218,  15626,   4114,   1943,  23046,  13453,\n",
      "           1327,  14435,  23046,    822,  23046,   8684,   9735],\n",
      "        [ 23046,   6842,   1476,   7510,   7169,  10409,   8707,  26007,\n",
      "            822,  23046,    431,  14309,   8707,   3823,  23537],\n",
      "        [ 23046,  12441,   8030,   1327,  14435,  23046,  17528,   2667,\n",
      "           1327,  14435,  23046,  17732,  12713,  15400,      0],\n",
      "        [  7510,  20793,  15618,  12713,  23046,  12791,  25218,  23046,\n",
      "          17167,    822,  24669,   7515,  23046,  18044,      0],\n",
      "        [ 23046,  14314,   9294,  15788,  21337,   3638,  13949,  12713,\n",
      "           7510,   5053,  10977,  26444,  13598,  14803,      0],\n",
      "        [ 17913,   1770,  15860,  23543,  21867,  23283,   9473,   1943,\n",
      "           8707,  18903,  12713,   7510,  27247,      0,      0],\n",
      "        [  9993,  17498,   1943,  23046,  20486,  15626,   3506,  11978,\n",
      "           7512,  10073,  25749,  23046,   2874,      0,      0],\n",
      "        [ 23046,   2707,  14803,  12713,  23046,  17159,  17959,    822,\n",
      "          23046,  26494,  10409,  21418,    196,      0,      0],\n",
      "        [ 23046,   3305,  10400,  22559,  23046,  22728,   4767,  23225,\n",
      "           7298,   1943,   8707,  19712,      0,      0,      0],\n",
      "        [ 23046,   7704,  12713,  24983,   3646,  10409,   8707,  15586,\n",
      "           8430,  23046,  10989,      0,      0,      0,      0],\n",
      "        [ 23046,   6983,  12713,   3305,   8030,   1327,  14435,  23046,\n",
      "          22728,  19712,  10138,      0,      0,      0,      0],\n",
      "        [ 23046,  23624,  12713,  24085,  24027,   6377,   4114,   1327,\n",
      "          14435,   4049,  13574,      0,      0,      0,      0],\n",
      "        [ 23046,   6983,  12713,     45,   4114,   1943,  18903,  12713,\n",
      "          23046,  14205,    437,      0,      0,      0,      0],\n",
      "        [ 23046,  17498,   8030,   1943,  23046,  15355,    822,  23283,\n",
      "          16211,   7298,  22813,      0,      0,      0,      0],\n",
      "        [ 23046,  23157,  20528,  16936,    822,  24520,  13672,  12713,\n",
      "          22740,  10409,  10402,      0,      0,      0,      0],\n",
      "        [ 23046,  23624,  12713,  21593,   1943,  23046,  23876,  25127,\n",
      "          12713,  26007,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   2707,  14803,  12713,  23046,   9787,  26921,  11754,\n",
      "          26444,   8297,      0,      0,      0,      0,      0],\n",
      "        [  8907,  23543,  24881,   1943,  23046,  17528,  25698,   7911,\n",
      "           7510,   5242,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   6842,  10400,   7810,  23046,  22728,   8279,    822,\n",
      "          23046,   4767,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   8514,  13499,   3638,  14435,  15166,  26007,   6273,\n",
      "          23046,  19708,      0,      0,      0,      0,      0],\n",
      "        [ 24085,  18268,  20118,   1943,  21473,    822,  14741,  26444,\n",
      "          23046,  20577,      0,      0,      0,      0,      0],\n",
      "        [ 24085,   6850,  19576,  10409,  23046,   5387,   8428,  23046,\n",
      "          15395,   5937,      0,      0,      0,      0,      0],\n",
      "        [ 16996,  26444,   1334,   3823,  10409,   2512,  22921,   1327,\n",
      "          14435,  22984,      0,      0,      0,      0,      0],\n",
      "        [  5741,  10400,   7510,   7474,  12713,  23046,   8107,   1943,\n",
      "           8707,  13453,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  23624,  12713,  14845,  18268,   4114,   1327,  14435,\n",
      "           4049,  13574,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  26154,    222,  15703,    822,  17049,  17145,  18856,\n",
      "          26444,   9878,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   5387,  21464,  12713,   9911,   3547,   3614,   7515,\n",
      "           7510,  11063,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  15298,  11824,  25689,   1943,  23046,  11905,   4225,\n",
      "          23046,  14158,      0,      0,      0,      0,      0],\n",
      "        [  7016,  10409,  25391,    472,  15526,   8983,  10409,  23046,\n",
      "          26683,      0,      0,      0,      0,      0,      0],\n",
      "        [  6609,   1770,   5353,   1943,   2523,   1327,  14435,  13574,\n",
      "           1770,      0,      0,      0,      0,      0,      0],\n",
      "        [ 24085,   8907,  10409,  23046,  26225,  16109,   8428,  23283,\n",
      "          15860,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   1334,    822,  21418,   8010,  25657,  23046,   3994,\n",
      "          15790,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  20086,  26154,   1899,    822,  14156,   2459,  26444,\n",
      "           6329,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  17498,  22737,  10400,   8030,  14309,  10409,  23046,\n",
      "          22955,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  26511,  22737,  10400,   4114,   1943,  23046,  25764,\n",
      "          27009,      0,      0,      0,      0,      0,      0],\n",
      "        [  5741,  23543,   7016,   7515,  23046,  26814,   7489,   7527,\n",
      "           2149,      0,      0,      0,      0,      0,      0],\n",
      "        [  9992,  10409,  18226,  12713,  23046,  17498,   1476,  23046,\n",
      "          21846,      0,      0,      0,      0,      0,      0],\n",
      "        [  7510,   6842,  25486,  10402,   1943,  23046,  24785,  10464,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 21304,   7298,   1888,   6273,   9911,  21846,   7911,   5966,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [  8707,  17913,  21083,  23543,   4111,  20218,  16446,   8797,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  11905,  14018,   8428,  23046,  25127,  12713,  26007,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 21796,  24867,    335,  23046,   3799,   1943,  21418,    923,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 10073,  10400,  10739,  26444,  27227,   4861,  26652,   4676,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 17913,   8983,  22737,  23543,   8030,  10409,   8707,   5758,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,  14164,   8064,  22559,  23046,  20070,   7368,  25328,\n",
      "              0,      0,      0,      0,      0,      0,      0],\n",
      "        [ 23046,   6842,   1476,  10556,   1943,  23046,  22531,   3126,\n",
      "              0,      0,      0,      0,      0,      0,      0]])\n"
     ]
    }
   ],
   "source": [
    "print(captions.type())\n",
    "print(captions.size())\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 15])\n",
      "tensor([[ 11668,  12098,   2662,  15455,  15185,  10306,   6496,  22388,\n",
      "            366,    283,  14938,   3638,  18888,   2598,  21660],\n",
      "        [ 12028,   5654,  13752,  21115,   3584,  11413,  16984,   9818,\n",
      "           2144,   4163,   8200,   3056,  18869,   8373,  16521],\n",
      "        [ 17606,     58,    870,   3119,  15609,  20938,  15537,  18282,\n",
      "          20109,   5292,  17121,  16849,   4809,   4832,  10013],\n",
      "        [  7315,  16826,  20212,  16158,   1352,  18028,   9202,  13897,\n",
      "          15043,  19434,  14067,   3237,  13822,  11535,   6125],\n",
      "        [ 10124,   1259,   6210,   2046,   7866,  21490,  14073,  14276,\n",
      "          12912,   9276,  16102,   4282,  11358,  19185,  17393],\n",
      "        [  4033,   6821,  21362,  21832,  23001,  10885,  21415,   6851,\n",
      "           2076,   5379,  21921,   8077,   1631,  10898,  11493],\n",
      "        [  3971,   2381,  10953,   5514,   4727,  17529,   3354,   9348,\n",
      "          17886,  13089,   7718,  16071,  18400,  19825,  16861],\n",
      "        [ 20006,   1319,  22186,  18700,  11000,  20265,    299,  17778,\n",
      "          13477,  12303,   2053,  10832,   4433,   2892,   2137],\n",
      "        [ 15493,  22824,  13498,   9664,  19497,    514,  22875,  15858,\n",
      "          14315,   9812,  21916,   4643,   6209,  14533,    792],\n",
      "        [  3483,  13281,  20424,  13263,  19852,   7150,   1015,  15971,\n",
      "          17648,   5467,  18641,   5737,  22547,   5158,  18875],\n",
      "        [  3567,  15405,  18409,  15771,  19053,   8731,  21769,  12762,\n",
      "            745,  21511,  22145,  16766,  17582,   1939,   8768],\n",
      "        [ 14441,   8453,   5154,   2933,   4339,  21962,    774,  21308,\n",
      "          13314,   8660,  10855,   3084,  15055,    816,  17651],\n",
      "        [ 13520,  18582,  14987,   7504,  22976,  15259,  15392,  16029,\n",
      "          18477,  12661,   3793,   9174,  13471,  16211,   1744],\n",
      "        [ 22228,    650,   3502,  16758,  21304,   6205,  18968,  12711,\n",
      "            277,  22265,   9392,  18445,   9399,  10659,  15741],\n",
      "        [ 15977,  18026,  14599,  16231,   5079,   4068,  21966,   7768,\n",
      "           8147,  22450,  22089,  20026,  19902,  12517,   3980],\n",
      "        [  9733,   3365,   1284,   2746,   5938,   1945,   5375,   4707,\n",
      "          18780,   5821,  11129,   2864,  19021,   7863,  12378],\n",
      "        [  6206,   2432,   6891,  16783,  17912,  16664,  23015,   1997,\n",
      "           5253,  11498,   1266,  10954,  21167,   9445,   4707],\n",
      "        [ 17533,  16189,   3755,   3614,   9247,   9206,   8046,   3908,\n",
      "           8643,  22603,   2134,   8241,   1343,   5704,   6709],\n",
      "        [ 15632,   3475,   7874,  17684,   4709,   2742,  14770,    777,\n",
      "          15334,  13337,  14960,  20109,  11188,   3420,  19141],\n",
      "        [  9136,   1107,  21482,  18013,  12626,  20952,  15403,  20399,\n",
      "           9602,  19410,  13234,   4329,   7982,  14199,  20185],\n",
      "        [ 10824,  10007,    313,  10872,   2966,   7738,  20247,   8953,\n",
      "          12257,  21185,   1522,   8609,  14164,  12392,   8660],\n",
      "        [  6325,   3969,   2489,  16738,   9448,  21519,  22653,  22273,\n",
      "          12001,  17164,   5645,   6872,   9701,  18603,  13613],\n",
      "        [ 17182,  20789,  15969,  17139,   2274,   9993,   9251,  19391,\n",
      "          17681,  20955,   4713,   8197,  20093,  17000,  12844],\n",
      "        [  8765,  21548,  15054,   3864,  17056,  20600,   9631,  21170,\n",
      "            573,  11395,    185,   3119,   5882,   6874,  21106],\n",
      "        [  9933,  10675,  11122,   5701,  11581,  20859,  15012,  12496,\n",
      "          19996,   7731,   8099,  19971,   6061,  18773,   4537],\n",
      "        [ 15718,  12867,  13129,   2715,   6648,  14806,   4401,  16071,\n",
      "           9685,    880,  16241,  21870,   2536,   3460,  10404],\n",
      "        [  2960,  21342,  14544,  10564,   4530,    584,   6598,  10984,\n",
      "          14273,  14884,  20480,   6344,  11148,   1644,  21337],\n",
      "        [ 10216,  16588,  16429,  22348,   3577,  18831,  15486,  11909,\n",
      "          16249,   5264,  12904,   8181,    973,   2946,  21818],\n",
      "        [  8850,  14374,  16327,   3915,   4748,  19519,  17876,   2690,\n",
      "          10204,  22473,  18910,  22336,  12083,   9245,   2334],\n",
      "        [ 13425,  13934,   5190,    329,   5373,   9258,  12825,  22119,\n",
      "           7752,   2594,   9446,  18485,   9683,  10591,  19509],\n",
      "        [ 21018,  16333,   4119,   8031,   1693,   1021,  21475,   5149,\n",
      "          12245,    584,   4652,   4251,    344,  15115,   9206],\n",
      "        [  4298,  20022,  16453,   6474,   9079,  16031,  12194,  14477,\n",
      "          21268,   8261,  14570,  13008,  17547,   8043,    857],\n",
      "        [  6378,  18163,  17848,  15491,    511,   4362,  13292,  12344,\n",
      "           7416,   7870,  16171,   6047,   4308,  19357,  13438],\n",
      "        [  6538,  10381,  20318,    620,    949,   1880,   6358,  16744,\n",
      "          10139,  12797,   3975,  19087,   4077,   1043,   3507],\n",
      "        [ 17424,   3773,  18668,  21594,  19070,  21058,  17020,  16433,\n",
      "          20328,  14801,   3558,   6415,  19744,  21628,  22207],\n",
      "        [  8057,   8455,  16543,  20549,  12304,  19610,  17062,  14193,\n",
      "             70,  15867,   9860,    257,  13718,   7753,   3813],\n",
      "        [ 14838,  18715,    352,  13264,  19949,   7324,  16585,  19923,\n",
      "           4039,   7062,  14555,  10203,   4801,  22197,  21327],\n",
      "        [ 17598,  21342,  20354,  14084,   6330,  15666,  13572,  21316,\n",
      "           3398,     29,   5800,   3269,   6944,  16204,  14416],\n",
      "        [  5513,  18234,  18759,   4828,  10643,  17793,    951,   2346,\n",
      "           9821,  15563,  22331,  19243,  17905,  14947,  19368],\n",
      "        [ 17856,  20400,  14124,   8499,    998,   2877,  21581,  18010,\n",
      "           5464,  13734,   8225,  14092,  12755,  19249,   3368],\n",
      "        [  9409,   5653,  22359,   6844,  14608,  16208,   5861,  16069,\n",
      "           5426,   6787,  18934,  18660,  15905,  22317,   6911],\n",
      "        [  5914,  22921,  22440,  12120,  16191,   6630,  21858,   2269,\n",
      "          20529,  19598,  14954,   9320,   1978,  21561,  21309],\n",
      "        [  2360,  11045,  16209,  13499,  15702,  21277,   4391,   1578,\n",
      "          14893,  12045,  17680,   3763,   9481,  11088,  22137],\n",
      "        [ 19637,   8945,  17661,  14654,   4038,  15731,  22984,  17697,\n",
      "          15112,  22400,   6967,     42,   3593,  20259,   1610],\n",
      "        [  4266,   4333,   3146,  22339,   1167,  20013,  18185,   9275,\n",
      "           8622,  10264,   9846,   3195,   4324,   5349,  14807],\n",
      "        [   748,   1497,   3002,    471,   6593,   7503,   8354,   4579,\n",
      "          20760,   4663,  15253,  13652,  20436,   3942,  14437],\n",
      "        [  7014,  16539,    769,     78,   4206,  14143,   8869,  14707,\n",
      "           2911,  10227,   3663,  21828,   6325,  17963,  13887],\n",
      "        [ 17214,  22033,   3495,   2597,   4660,  19460,  12463,  11566,\n",
      "          13189,   6924,  18220,   5245,  19071,   1499,  14553]])\n"
     ]
    }
   ],
   "source": [
    "# captions_dummy_input = torch.rand(48, 15, requires_grad=True)\n",
    "captions_fake_input = torch.randint(1, 23046, (48, 15), dtype=torch.long)\n",
    "# captions_dummy_input = torch.rand(48, 15, requires_grad=True)\n",
    "print(captions_fake_input.size())\n",
    "print(captions_fake_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "torch.Size([48])\n",
      "tensor([ 15,  15,  15,  15,  14,  14,  14,  13,  13,  13,  12,  11,\n",
      "         11,  11,  11,  11,  11,  10,  10,  10,  10,  10,  10,  10,\n",
      "         10,  10,  10,  10,  10,  10,   9,   9,   9,   9,   9,   9,\n",
      "          9,   9,   9,   8,   8,   8,   8,   8,   8,   8,   8,   8])\n"
     ]
    }
   ],
   "source": [
    "print(cap_lens.type())\n",
    "print(cap_lens.size())\n",
    "print(cap_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48])\n",
      "tensor([ 13,   7,   6,  13,  14,   7,   6,   8,   4,  14,   1,  14,\n",
      "         12,   4,   6,   5,   6,   8,   5,   5,   7,   9,   2,  11,\n",
      "          3,  13,  12,  13,   1,  12,   6,   9,  12,  11,  12,  14,\n",
      "         13,  13,   7,   2,   2,   9,   7,   2,   2,   3,   4,   6])\n"
     ]
    }
   ],
   "source": [
    "# cap_lens_fake_input = torch.rand(48, dtype=torch.float64)\n",
    "cap_lens_fake_input = torch.randint(1, 15, (48,), dtype=torch.long)\n",
    "# cap_lens_dummy_input = torch.FloatTensor(cap_lens_dummy_input)\n",
    "print(cap_lens_fake_input.size())\n",
    "print(cap_lens_fake_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden[0].shape:  torch.Size([2, 48, 128])  and data type:  torch.FloatTensor\n",
      "hidden[1].shape:  torch.Size([2, 48, 128])  and data type:  torch.FloatTensor\n",
      "(tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]), tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]))\n"
     ]
    }
   ],
   "source": [
    "print(\"hidden[0].shape: \", hidden[0].shape, \" and data type: \", hidden[0].type())\n",
    "print(\"hidden[1].shape: \", hidden[1].shape, \" and data type: \", hidden[1].type())\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 48, 128])\n",
      "tensor([[[ 8,  8,  5,  ...,  1,  5,  4],\n",
      "         [ 8,  4,  3,  ...,  2,  1,  9],\n",
      "         [ 1,  1,  2,  ...,  1,  8,  3],\n",
      "         ...,\n",
      "         [ 3,  2,  3,  ...,  3,  5,  3],\n",
      "         [ 3,  4,  3,  ...,  3,  9,  1],\n",
      "         [ 7,  3,  1,  ...,  7,  3,  7]],\n",
      "\n",
      "        [[ 3,  8,  1,  ...,  4,  3,  8],\n",
      "         [ 1,  2,  7,  ...,  9,  6,  8],\n",
      "         [ 5,  1,  6,  ...,  5,  6,  5],\n",
      "         ...,\n",
      "         [ 7,  8,  3,  ...,  9,  8,  7],\n",
      "         [ 6,  4,  2,  ...,  1,  3,  1],\n",
      "         [ 5,  6,  4,  ...,  9,  2,  9]]])\n"
     ]
    }
   ],
   "source": [
    "# hidden_fake_input = torch.randint(0, 1 (2, 48, 128), dtype=torch.long)\n",
    "hidden_fake_input = torch.randint(1, 10, (2, 48, 128), dtype=torch.long)\n",
    "# hidden_fake_input = torch.FloatTensor(hidden_fake_input)\n",
    "print(hidden_fake_input.size())\n",
    "print(hidden_fake_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output = text_encoder(captions, cap_lens, hidden)\n",
    "words_emb, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
    "\n",
    "r = (captions, cap_lens, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 23046,  15790,   4114,   1943,  23046,   2861,  20752,  26444,\n",
       "           13598,   7515,  23046,   7510,  13540,   1943,  10402],\n",
       "         [ 23046,   8494,  26444,  16860,  11824,  10409,  23484,  23046,\n",
       "           15298,  15788,  10400,   1327,  14435,  23046,  14018],\n",
       "         [ 23046,  18903,  25218,  15626,   4114,   1943,  23046,  13453,\n",
       "            1327,  14435,  23046,    822,  23046,   8684,   9735],\n",
       "         [ 23046,   6842,   1476,   7510,   7169,  10409,   8707,  26007,\n",
       "             822,  23046,    431,  14309,   8707,   3823,  23537],\n",
       "         [ 23046,  12441,   8030,   1327,  14435,  23046,  17528,   2667,\n",
       "            1327,  14435,  23046,  17732,  12713,  15400,      0],\n",
       "         [  7510,  20793,  15618,  12713,  23046,  12791,  25218,  23046,\n",
       "           17167,    822,  24669,   7515,  23046,  18044,      0],\n",
       "         [ 23046,  14314,   9294,  15788,  21337,   3638,  13949,  12713,\n",
       "            7510,   5053,  10977,  26444,  13598,  14803,      0],\n",
       "         [ 17913,   1770,  15860,  23543,  21867,  23283,   9473,   1943,\n",
       "            8707,  18903,  12713,   7510,  27247,      0,      0],\n",
       "         [  9993,  17498,   1943,  23046,  20486,  15626,   3506,  11978,\n",
       "            7512,  10073,  25749,  23046,   2874,      0,      0],\n",
       "         [ 23046,   2707,  14803,  12713,  23046,  17159,  17959,    822,\n",
       "           23046,  26494,  10409,  21418,    196,      0,      0],\n",
       "         [ 23046,   3305,  10400,  22559,  23046,  22728,   4767,  23225,\n",
       "            7298,   1943,   8707,  19712,      0,      0,      0],\n",
       "         [ 23046,   7704,  12713,  24983,   3646,  10409,   8707,  15586,\n",
       "            8430,  23046,  10989,      0,      0,      0,      0],\n",
       "         [ 23046,   6983,  12713,   3305,   8030,   1327,  14435,  23046,\n",
       "           22728,  19712,  10138,      0,      0,      0,      0],\n",
       "         [ 23046,  23624,  12713,  24085,  24027,   6377,   4114,   1327,\n",
       "           14435,   4049,  13574,      0,      0,      0,      0],\n",
       "         [ 23046,   6983,  12713,     45,   4114,   1943,  18903,  12713,\n",
       "           23046,  14205,    437,      0,      0,      0,      0],\n",
       "         [ 23046,  17498,   8030,   1943,  23046,  15355,    822,  23283,\n",
       "           16211,   7298,  22813,      0,      0,      0,      0],\n",
       "         [ 23046,  23157,  20528,  16936,    822,  24520,  13672,  12713,\n",
       "           22740,  10409,  10402,      0,      0,      0,      0],\n",
       "         [ 23046,  23624,  12713,  21593,   1943,  23046,  23876,  25127,\n",
       "           12713,  26007,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   2707,  14803,  12713,  23046,   9787,  26921,  11754,\n",
       "           26444,   8297,      0,      0,      0,      0,      0],\n",
       "         [  8907,  23543,  24881,   1943,  23046,  17528,  25698,   7911,\n",
       "            7510,   5242,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   6842,  10400,   7810,  23046,  22728,   8279,    822,\n",
       "           23046,   4767,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   8514,  13499,   3638,  14435,  15166,  26007,   6273,\n",
       "           23046,  19708,      0,      0,      0,      0,      0],\n",
       "         [ 24085,  18268,  20118,   1943,  21473,    822,  14741,  26444,\n",
       "           23046,  20577,      0,      0,      0,      0,      0],\n",
       "         [ 24085,   6850,  19576,  10409,  23046,   5387,   8428,  23046,\n",
       "           15395,   5937,      0,      0,      0,      0,      0],\n",
       "         [ 16996,  26444,   1334,   3823,  10409,   2512,  22921,   1327,\n",
       "           14435,  22984,      0,      0,      0,      0,      0],\n",
       "         [  5741,  10400,   7510,   7474,  12713,  23046,   8107,   1943,\n",
       "            8707,  13453,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  23624,  12713,  14845,  18268,   4114,   1327,  14435,\n",
       "            4049,  13574,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  26154,    222,  15703,    822,  17049,  17145,  18856,\n",
       "           26444,   9878,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   5387,  21464,  12713,   9911,   3547,   3614,   7515,\n",
       "            7510,  11063,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  15298,  11824,  25689,   1943,  23046,  11905,   4225,\n",
       "           23046,  14158,      0,      0,      0,      0,      0],\n",
       "         [  7016,  10409,  25391,    472,  15526,   8983,  10409,  23046,\n",
       "           26683,      0,      0,      0,      0,      0,      0],\n",
       "         [  6609,   1770,   5353,   1943,   2523,   1327,  14435,  13574,\n",
       "            1770,      0,      0,      0,      0,      0,      0],\n",
       "         [ 24085,   8907,  10409,  23046,  26225,  16109,   8428,  23283,\n",
       "           15860,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   1334,    822,  21418,   8010,  25657,  23046,   3994,\n",
       "           15790,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  20086,  26154,   1899,    822,  14156,   2459,  26444,\n",
       "            6329,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  17498,  22737,  10400,   8030,  14309,  10409,  23046,\n",
       "           22955,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  26511,  22737,  10400,   4114,   1943,  23046,  25764,\n",
       "           27009,      0,      0,      0,      0,      0,      0],\n",
       "         [  5741,  23543,   7016,   7515,  23046,  26814,   7489,   7527,\n",
       "            2149,      0,      0,      0,      0,      0,      0],\n",
       "         [  9992,  10409,  18226,  12713,  23046,  17498,   1476,  23046,\n",
       "           21846,      0,      0,      0,      0,      0,      0],\n",
       "         [  7510,   6842,  25486,  10402,   1943,  23046,  24785,  10464,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 21304,   7298,   1888,   6273,   9911,  21846,   7911,   5966,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [  8707,  17913,  21083,  23543,   4111,  20218,  16446,   8797,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  11905,  14018,   8428,  23046,  25127,  12713,  26007,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 21796,  24867,    335,  23046,   3799,   1943,  21418,    923,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 10073,  10400,  10739,  26444,  27227,   4861,  26652,   4676,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 17913,   8983,  22737,  23543,   8030,  10409,   8707,   5758,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,  14164,   8064,  22559,  23046,  20070,   7368,  25328,\n",
       "               0,      0,      0,      0,      0,      0,      0],\n",
       "         [ 23046,   6842,   1476,  10556,   1943,  23046,  22531,   3126,\n",
       "               0,      0,      0,      0,      0,      0,      0]]),\n",
       " tensor([ 15,  15,  15,  15,  14,  14,  14,  13,  13,  13,  12,  11,\n",
       "          11,  11,  11,  11,  11,  10,  10,  10,  10,  10,  10,  10,\n",
       "          10,  10,  10,  10,  10,  10,   9,   9,   9,   9,   9,   9,\n",
       "           9,   9,   9,   8,   8,   8,   8,   8,   8,   8,   8,   8]),\n",
       " (tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]),\n",
       "  tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 256, 15])\n",
      "tensor([[[-0.0164, -0.0309, -0.0140,  ..., -0.0535, -0.0200, -0.0187],\n",
      "         [-0.0042,  0.0009,  0.0209,  ...,  0.0270,  0.0321,  0.0131],\n",
      "         [-0.0017,  0.0320,  0.0279,  ...,  0.0503,  0.0445,  0.0481],\n",
      "         ...,\n",
      "         [ 0.0087,  0.0065,  0.0439,  ..., -0.0036,  0.0153,  0.0045],\n",
      "         [ 0.0239,  0.0305,  0.0259,  ...,  0.0180,  0.0014,  0.0068],\n",
      "         [ 0.0138, -0.0134, -0.0073,  ...,  0.0154, -0.0035, -0.0088]],\n",
      "\n",
      "        [[-0.0164, -0.0059,  0.0147,  ..., -0.0279, -0.0409, -0.0557],\n",
      "         [-0.0042, -0.0241,  0.0050,  ...,  0.0065, -0.0015, -0.0041],\n",
      "         [-0.0017, -0.0030,  0.0245,  ...,  0.0342,  0.0207,  0.0225],\n",
      "         ...,\n",
      "         [-0.0022, -0.0182,  0.0177,  ...,  0.0144,  0.0124,  0.0122],\n",
      "         [ 0.0201,  0.0294,  0.0232,  ..., -0.0077,  0.0132,  0.0022],\n",
      "         [ 0.0231, -0.0021, -0.0391,  ...,  0.0383,  0.0098, -0.0297]],\n",
      "\n",
      "        [[-0.0164,  0.0098, -0.0241,  ..., -0.0496, -0.0231, -0.0433],\n",
      "         [-0.0042,  0.0105, -0.0012,  ...,  0.0013,  0.0377,  0.0381],\n",
      "         [-0.0017,  0.0213,  0.0437,  ...,  0.0143,  0.0336,  0.0635],\n",
      "         ...,\n",
      "         [ 0.0069,  0.0036,  0.0183,  ...,  0.0088,  0.0043, -0.0030],\n",
      "         [ 0.0148,  0.0189,  0.0366,  ...,  0.0033, -0.0075, -0.0126],\n",
      "         [ 0.0129, -0.0155, -0.0150,  ...,  0.0245,  0.0031,  0.0193]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0078,  0.0070, -0.0278,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0023,  0.0031,  0.0098,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0317,  0.0223,  0.0558,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0219,  0.0147,  0.0105,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0084,  0.0015, -0.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0234,  0.0070, -0.0100,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0164, -0.0308, -0.0396,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0042, -0.0214, -0.0191,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0017, -0.0001,  0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0219,  0.0279,  0.0266,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0134,  0.0116,  0.0135,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0106, -0.0156,  0.0173,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0164, -0.0515, -0.0438,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0042,  0.0233,  0.0218,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0017,  0.0168,  0.0321,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0011, -0.0103, -0.0096,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0132,  0.0056,  0.0231,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0209, -0.0024, -0.0197,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(words_emb.shape)\n",
    "print(words_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 256])\n",
      "tensor([[-1.8697e-02,  1.3067e-02,  4.8063e-02,  ...,  8.6733e-03,\n",
      "          2.3882e-02,  1.3803e-02],\n",
      "        [-5.5712e-02, -4.1268e-03,  2.2523e-02,  ..., -2.2310e-03,\n",
      "          2.0061e-02,  2.3147e-02],\n",
      "        [-4.3290e-02,  3.8086e-02,  6.3508e-02,  ...,  6.8706e-03,\n",
      "          1.4765e-02,  1.2867e-02],\n",
      "        ...,\n",
      "        [-2.8123e-02,  1.6622e-02,  5.8342e-02,  ...,  2.1916e-02,\n",
      "          8.4493e-03, -2.3437e-02],\n",
      "        [-6.6720e-02,  1.4136e-02,  4.1421e-02,  ...,  2.1916e-02,\n",
      "          1.3408e-02,  1.0613e-02],\n",
      "        [-3.0940e-02, -9.0442e-03,  4.4092e-02,  ..., -1.0927e-03,\n",
      "          1.3184e-02,  2.0895e-02]])\n"
     ]
    }
   ],
   "source": [
    "print(sent_emb.shape)\n",
    "print(sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.1.6 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n",
      "WARNING:root:TensorFlow version 1.8.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "# source coreml/bin/activate\n",
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output = text_encoder(captions, cap_lens, hidden)\n",
    "captions_fake_input = torch.randint(1, 23046, (48, 15), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_emb_, sent_emb_ = text_encoder(captions, cap_lens, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0164, -0.0309, -0.0140,  ..., -0.0535, -0.0200, -0.0187],\n",
       "         [-0.0042,  0.0009,  0.0209,  ...,  0.0270,  0.0321,  0.0131],\n",
       "         [-0.0017,  0.0320,  0.0279,  ...,  0.0503,  0.0445,  0.0481],\n",
       "         ...,\n",
       "         [ 0.0087,  0.0065,  0.0439,  ..., -0.0036,  0.0153,  0.0045],\n",
       "         [ 0.0239,  0.0305,  0.0259,  ...,  0.0180,  0.0014,  0.0068],\n",
       "         [ 0.0138, -0.0134, -0.0073,  ...,  0.0154, -0.0035, -0.0088]],\n",
       "\n",
       "        [[-0.0164, -0.0059,  0.0147,  ..., -0.0279, -0.0409, -0.0557],\n",
       "         [-0.0042, -0.0241,  0.0050,  ...,  0.0065, -0.0015, -0.0041],\n",
       "         [-0.0017, -0.0030,  0.0245,  ...,  0.0342,  0.0207,  0.0225],\n",
       "         ...,\n",
       "         [-0.0022, -0.0182,  0.0177,  ...,  0.0144,  0.0124,  0.0122],\n",
       "         [ 0.0201,  0.0294,  0.0232,  ..., -0.0077,  0.0132,  0.0022],\n",
       "         [ 0.0231, -0.0021, -0.0391,  ...,  0.0383,  0.0098, -0.0297]],\n",
       "\n",
       "        [[-0.0164,  0.0098, -0.0241,  ..., -0.0496, -0.0231, -0.0433],\n",
       "         [-0.0042,  0.0105, -0.0012,  ...,  0.0013,  0.0377,  0.0381],\n",
       "         [-0.0017,  0.0213,  0.0437,  ...,  0.0143,  0.0336,  0.0635],\n",
       "         ...,\n",
       "         [ 0.0069,  0.0036,  0.0183,  ...,  0.0088,  0.0043, -0.0030],\n",
       "         [ 0.0148,  0.0189,  0.0366,  ...,  0.0033, -0.0075, -0.0126],\n",
       "         [ 0.0129, -0.0155, -0.0150,  ...,  0.0245,  0.0031,  0.0193]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0078,  0.0070, -0.0278,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0023,  0.0031,  0.0098,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0317,  0.0223,  0.0558,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0219,  0.0147,  0.0105,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0084,  0.0015, -0.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0234,  0.0070, -0.0100,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0164, -0.0308, -0.0396,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0042, -0.0214, -0.0191,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0017, -0.0001,  0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0219,  0.0279,  0.0266,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0134,  0.0116,  0.0135,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0106, -0.0156,  0.0173,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0164, -0.0515, -0.0438,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0042,  0.0233,  0.0218,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0017,  0.0168,  0.0321,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0011, -0.0103, -0.0096,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0132,  0.0056,  0.0231,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0209, -0.0024, -0.0197,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_emb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8697e-02,  1.3067e-02,  4.8063e-02,  ...,  8.6733e-03,\n",
       "          2.3882e-02,  1.3803e-02],\n",
       "        [-5.5712e-02, -4.1268e-03,  2.2523e-02,  ..., -2.2310e-03,\n",
       "          2.0061e-02,  2.3147e-02],\n",
       "        [-4.3290e-02,  3.8086e-02,  6.3508e-02,  ...,  6.8706e-03,\n",
       "          1.4765e-02,  1.2867e-02],\n",
       "        ...,\n",
       "        [-2.8123e-02,  1.6622e-02,  5.8342e-02,  ...,  2.1916e-02,\n",
       "          8.4493e-03, -2.3437e-02],\n",
       "        [-6.6720e-02,  1.4136e-02,  4.1421e-02,  ...,  2.1916e-02,\n",
       "          1.3408e-02,  1.0613e-02],\n",
       "        [-3.0940e-02, -9.0442e-03,  4.4092e-02,  ..., -1.0927e-03,\n",
       "          1.3184e-02,  2.0895e-02]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_emb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_ENCODER(\n",
       "  (encoder): Embedding(27297, 300)\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (rnn): LSTM(300, 128, batch_first=True, dropout=0.5, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# captions_fake_input = captions_fake_input.float()\n",
    "cap_lens = cap_lens.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_fake_input.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "wrapPyFuncWithSymbolic(): incompatible function arguments. The following argument types are supported:\n    1. (self: torch._C.Graph, arg0: function, arg1: List[torch::jit::Value], arg2: int, arg3: function) -> iterator\n\nInvoked with: graph(%0 : Long(48, 15)\n      %1 : Float(48)\n      %2 : Float(2, 48, 128)\n      %3 : Float(2, 48, 128)\n      %4 : Float(27297, 300)\n      %5 : Float(512, 300)\n      %6 : Float(512, 128)\n      %7 : Float(512)\n      %8 : Float(512)\n      %9 : Float(512, 300)\n      %10 : Float(512, 128)\n      %11 : Float(512)\n      %12 : Float(512)) {\n  %13 : Float(48, 15, 300) = aten::embedding[padding_idx=-1, scale_grad_by_freq=0, sparse=0](%4, %0), scope: RNN_ENCODER/Embedding[encoder]\n  %16 : Float(48, 15, 300), %17 : Handle = ^Dropout(0.5, False, False)(%13), scope: RNN_ENCODER/Dropout[drop]\n  %15 : Float(48, 15, 300) = aten::slice[dim=0, start=0, end=9223372036854775807, step=1](%13), scope: RNN_ENCODER/Dropout[drop]\n  %14 : Float(48, 15, 300) = aten::as_strided[size=[48, 15, 300], stride=[4500, 300, 1], storage_offset=0](%13), scope: RNN_ENCODER/Dropout[drop]\n  %18 : Long(48) = prim::Constant[value=<Tensor>](), scope: RNN_ENCODER\n  %70 : Float(502, 300), %71 : Long(15), %72 : Handle = ^PackPadded(True)(%16, %18), scope: RNN_ENCODER\n  %19 : Float(15!, 48!, 300) = aten::transpose[dim0=0, dim1=1](%16), scope: RNN_ENCODER\n  %21 : Long() = aten::select[dim=0, index=47](%18), scope: RNN_ENCODER\n  %20 : Long() = aten::as_strided[size=[], stride=[], storage_offset=47](%18), scope: RNN_ENCODER\n  %22 : Byte() = aten::le[other={0}](%21), scope: RNN_ENCODER\n  %24 : Float(8!, 48!, 300) = aten::slice[dim=0, start=0, end=8, step=1](%19), scope: RNN_ENCODER\n  %23 : Float(8!, 48!, 300) = aten::as_strided[size=[8, 48, 300], stride=[300, 4500, 1], storage_offset=0](%19), scope: RNN_ENCODER\n  %25 : Float(8, 48, 300) = aten::clone(%24), scope: RNN_ENCODER\n  %26 : Float(384, 300) = aten::view[size=[-1, 300]](%25), scope: RNN_ENCODER\n  %28 : Float(1!, 48!, 300) = aten::slice[dim=0, start=8, end=9, step=1](%19), scope: RNN_ENCODER\n  %27 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=2400](%19), scope: RNN_ENCODER\n  %30 : Float(1!, 39!, 300) = aten::slice[dim=1, start=0, end=39, step=1](%28), scope: RNN_ENCODER\n  %29 : Float(1!, 39!, 300) = aten::as_strided[size=[1, 39, 300], stride=[300, 4500, 1], storage_offset=2400](%28), scope: RNN_ENCODER\n  %31 : Float(1, 39, 300) = aten::clone(%30), scope: RNN_ENCODER\n  %32 : Float(39, 300) = aten::view[size=[-1, 300]](%31), scope: RNN_ENCODER\n  %34 : Float(1!, 48!, 300) = aten::slice[dim=0, start=9, end=10, step=1](%19), scope: RNN_ENCODER\n  %33 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=2700](%19), scope: RNN_ENCODER\n  %36 : Float(1!, 30!, 300) = aten::slice[dim=1, start=0, end=30, step=1](%34), scope: RNN_ENCODER\n  %35 : Float(1!, 30!, 300) = aten::as_strided[size=[1, 30, 300], stride=[300, 4500, 1], storage_offset=2700](%34), scope: RNN_ENCODER\n  %37 : Float(1, 30, 300) = aten::clone(%36), scope: RNN_ENCODER\n  %38 : Float(30, 300) = aten::view[size=[-1, 300]](%37), scope: RNN_ENCODER\n  %40 : Float(1!, 48!, 300) = aten::slice[dim=0, start=10, end=11, step=1](%19), scope: RNN_ENCODER\n  %39 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3000](%19), scope: RNN_ENCODER\n  %42 : Float(1!, 17!, 300) = aten::slice[dim=1, start=0, end=17, step=1](%40), scope: RNN_ENCODER\n  %41 : Float(1!, 17!, 300) = aten::as_strided[size=[1, 17, 300], stride=[300, 4500, 1], storage_offset=3000](%40), scope: RNN_ENCODER\n  %43 : Float(1, 17, 300) = aten::clone(%42), scope: RNN_ENCODER\n  %44 : Float(17, 300) = aten::view[size=[-1, 300]](%43), scope: RNN_ENCODER\n  %46 : Float(1!, 48!, 300) = aten::slice[dim=0, start=11, end=12, step=1](%19), scope: RNN_ENCODER\n  %45 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3300](%19), scope: RNN_ENCODER\n  %48 : Float(1!, 11!, 300) = aten::slice[dim=1, start=0, end=11, step=1](%46), scope: RNN_ENCODER\n  %47 : Float(1!, 11!, 300) = aten::as_strided[size=[1, 11, 300], stride=[300, 4500, 1], storage_offset=3300](%46), scope: RNN_ENCODER\n  %49 : Float(1, 11, 300) = aten::clone(%48), scope: RNN_ENCODER\n  %50 : Float(11, 300) = aten::view[size=[-1, 300]](%49), scope: RNN_ENCODER\n  %52 : Float(1!, 48!, 300) = aten::slice[dim=0, start=12, end=13, step=1](%19), scope: RNN_ENCODER\n  %51 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3600](%19), scope: RNN_ENCODER\n  %54 : Float(1!, 10!, 300) = aten::slice[dim=1, start=0, end=10, step=1](%52), scope: RNN_ENCODER\n  %53 : Float(1!, 10!, 300) = aten::as_strided[size=[1, 10, 300], stride=[300, 4500, 1], storage_offset=3600](%52), scope: RNN_ENCODER\n  %55 : Float(1, 10, 300) = aten::clone(%54), scope: RNN_ENCODER\n  %56 : Float(10, 300) = aten::view[size=[-1, 300]](%55), scope: RNN_ENCODER\n  %58 : Float(1!, 48!, 300) = aten::slice[dim=0, start=13, end=14, step=1](%19), scope: RNN_ENCODER\n  %57 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3900](%19), scope: RNN_ENCODER\n  %60 : Float(1!, 7!, 300) = aten::slice[dim=1, start=0, end=7, step=1](%58), scope: RNN_ENCODER\n  %59 : Float(1!, 7!, 300) = aten::as_strided[size=[1, 7, 300], stride=[300, 4500, 1], storage_offset=3900](%58), scope: RNN_ENCODER\n  %61 : Float(1, 7, 300) = aten::clone(%60), scope: RNN_ENCODER\n  %62 : Float(7, 300) = aten::view[size=[-1, 300]](%61), scope: RNN_ENCODER\n  %64 : Float(1!, 48!, 300) = aten::slice[dim=0, start=14, end=15, step=1](%19), scope: RNN_ENCODER\n  %63 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=4200](%19), scope: RNN_ENCODER\n  %66 : Float(1!, 4!, 300) = aten::slice[dim=1, start=0, end=4, step=1](%64), scope: RNN_ENCODER\n  %65 : Float(1!, 4!, 300) = aten::as_strided[size=[1, 4, 300], stride=[300, 4500, 1], storage_offset=4200](%64), scope: RNN_ENCODER\n  %67 : Float(1, 4, 300) = aten::clone(%66), scope: RNN_ENCODER\n  %68 : Float(4, 300) = aten::view[size=[-1, 300]](%67), scope: RNN_ENCODER\n  %69 : Float(502, 300) = aten::cat[dim=0](%26, %32, %38, %44, %50, %56, %62, %68), scope: RNN_ENCODER\n  return ();\n}\n, <function _symbolic_pack_padded_sequence.<locals>.pack_padded_sequence_trace_wrapper at 0x1c28bcb2f0>, [16 defined in (%16 : Float(48, 15, 300), %17 : Handle = ^Dropout(0.5, False, False)(%13), scope: RNN_ENCODER/Dropout[drop]\n), [15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0]], 2, <function _symbolic_pack_padded_sequence.<locals>._onnx_symbolic_pack_padded_sequence at 0x1c37cfd950>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6144a753f443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                \u001b[0;34m(\u001b[0m\u001b[0mcaptions_fake_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# model input (or a tuple for multiple inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0;34m\"kol.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# where to save the model (can be a file or file-like object)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                export_params=True)           # store the trained parameter weights inside the model file\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mas\u001b[0m \u001b[0mATen\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_type)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# training mode was.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_state_dict_keys\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mget_trace_graph\u001b[0;34m(f, args, kwargs, nderivs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLegacyTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnderivs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnderivs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0m_tracing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mtrace_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_trace_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mout_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0m_tracing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/text-to-image-transcribed/code/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, captions, cap_lens, hidden, mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m#print(\"======= Packed emb ====== \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m#print(\"emb: \", emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m#print(\"emb shape: \", emb.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0msymbolic_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0moutput_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msymbolic_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         for var, val in zip(\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36m_symbolic_pack_padded_sequence\u001b[0;34m(g, input, lengths, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    144\u001b[0m     outputs = g.wrapPyFuncWithSymbolic(\n\u001b[1;32m    145\u001b[0m         \u001b[0mpack_padded_sequence_trace_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         _onnx_symbolic_pack_padded_sequence)\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: wrapPyFuncWithSymbolic(): incompatible function arguments. The following argument types are supported:\n    1. (self: torch._C.Graph, arg0: function, arg1: List[torch::jit::Value], arg2: int, arg3: function) -> iterator\n\nInvoked with: graph(%0 : Long(48, 15)\n      %1 : Float(48)\n      %2 : Float(2, 48, 128)\n      %3 : Float(2, 48, 128)\n      %4 : Float(27297, 300)\n      %5 : Float(512, 300)\n      %6 : Float(512, 128)\n      %7 : Float(512)\n      %8 : Float(512)\n      %9 : Float(512, 300)\n      %10 : Float(512, 128)\n      %11 : Float(512)\n      %12 : Float(512)) {\n  %13 : Float(48, 15, 300) = aten::embedding[padding_idx=-1, scale_grad_by_freq=0, sparse=0](%4, %0), scope: RNN_ENCODER/Embedding[encoder]\n  %16 : Float(48, 15, 300), %17 : Handle = ^Dropout(0.5, False, False)(%13), scope: RNN_ENCODER/Dropout[drop]\n  %15 : Float(48, 15, 300) = aten::slice[dim=0, start=0, end=9223372036854775807, step=1](%13), scope: RNN_ENCODER/Dropout[drop]\n  %14 : Float(48, 15, 300) = aten::as_strided[size=[48, 15, 300], stride=[4500, 300, 1], storage_offset=0](%13), scope: RNN_ENCODER/Dropout[drop]\n  %18 : Long(48) = prim::Constant[value=<Tensor>](), scope: RNN_ENCODER\n  %70 : Float(502, 300), %71 : Long(15), %72 : Handle = ^PackPadded(True)(%16, %18), scope: RNN_ENCODER\n  %19 : Float(15!, 48!, 300) = aten::transpose[dim0=0, dim1=1](%16), scope: RNN_ENCODER\n  %21 : Long() = aten::select[dim=0, index=47](%18), scope: RNN_ENCODER\n  %20 : Long() = aten::as_strided[size=[], stride=[], storage_offset=47](%18), scope: RNN_ENCODER\n  %22 : Byte() = aten::le[other={0}](%21), scope: RNN_ENCODER\n  %24 : Float(8!, 48!, 300) = aten::slice[dim=0, start=0, end=8, step=1](%19), scope: RNN_ENCODER\n  %23 : Float(8!, 48!, 300) = aten::as_strided[size=[8, 48, 300], stride=[300, 4500, 1], storage_offset=0](%19), scope: RNN_ENCODER\n  %25 : Float(8, 48, 300) = aten::clone(%24), scope: RNN_ENCODER\n  %26 : Float(384, 300) = aten::view[size=[-1, 300]](%25), scope: RNN_ENCODER\n  %28 : Float(1!, 48!, 300) = aten::slice[dim=0, start=8, end=9, step=1](%19), scope: RNN_ENCODER\n  %27 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=2400](%19), scope: RNN_ENCODER\n  %30 : Float(1!, 39!, 300) = aten::slice[dim=1, start=0, end=39, step=1](%28), scope: RNN_ENCODER\n  %29 : Float(1!, 39!, 300) = aten::as_strided[size=[1, 39, 300], stride=[300, 4500, 1], storage_offset=2400](%28), scope: RNN_ENCODER\n  %31 : Float(1, 39, 300) = aten::clone(%30), scope: RNN_ENCODER\n  %32 : Float(39, 300) = aten::view[size=[-1, 300]](%31), scope: RNN_ENCODER\n  %34 : Float(1!, 48!, 300) = aten::slice[dim=0, start=9, end=10, step=1](%19), scope: RNN_ENCODER\n  %33 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=2700](%19), scope: RNN_ENCODER\n  %36 : Float(1!, 30!, 300) = aten::slice[dim=1, start=0, end=30, step=1](%34), scope: RNN_ENCODER\n  %35 : Float(1!, 30!, 300) = aten::as_strided[size=[1, 30, 300], stride=[300, 4500, 1], storage_offset=2700](%34), scope: RNN_ENCODER\n  %37 : Float(1, 30, 300) = aten::clone(%36), scope: RNN_ENCODER\n  %38 : Float(30, 300) = aten::view[size=[-1, 300]](%37), scope: RNN_ENCODER\n  %40 : Float(1!, 48!, 300) = aten::slice[dim=0, start=10, end=11, step=1](%19), scope: RNN_ENCODER\n  %39 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3000](%19), scope: RNN_ENCODER\n  %42 : Float(1!, 17!, 300) = aten::slice[dim=1, start=0, end=17, step=1](%40), scope: RNN_ENCODER\n  %41 : Float(1!, 17!, 300) = aten::as_strided[size=[1, 17, 300], stride=[300, 4500, 1], storage_offset=3000](%40), scope: RNN_ENCODER\n  %43 : Float(1, 17, 300) = aten::clone(%42), scope: RNN_ENCODER\n  %44 : Float(17, 300) = aten::view[size=[-1, 300]](%43), scope: RNN_ENCODER\n  %46 : Float(1!, 48!, 300) = aten::slice[dim=0, start=11, end=12, step=1](%19), scope: RNN_ENCODER\n  %45 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3300](%19), scope: RNN_ENCODER\n  %48 : Float(1!, 11!, 300) = aten::slice[dim=1, start=0, end=11, step=1](%46), scope: RNN_ENCODER\n  %47 : Float(1!, 11!, 300) = aten::as_strided[size=[1, 11, 300], stride=[300, 4500, 1], storage_offset=3300](%46), scope: RNN_ENCODER\n  %49 : Float(1, 11, 300) = aten::clone(%48), scope: RNN_ENCODER\n  %50 : Float(11, 300) = aten::view[size=[-1, 300]](%49), scope: RNN_ENCODER\n  %52 : Float(1!, 48!, 300) = aten::slice[dim=0, start=12, end=13, step=1](%19), scope: RNN_ENCODER\n  %51 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3600](%19), scope: RNN_ENCODER\n  %54 : Float(1!, 10!, 300) = aten::slice[dim=1, start=0, end=10, step=1](%52), scope: RNN_ENCODER\n  %53 : Float(1!, 10!, 300) = aten::as_strided[size=[1, 10, 300], stride=[300, 4500, 1], storage_offset=3600](%52), scope: RNN_ENCODER\n  %55 : Float(1, 10, 300) = aten::clone(%54), scope: RNN_ENCODER\n  %56 : Float(10, 300) = aten::view[size=[-1, 300]](%55), scope: RNN_ENCODER\n  %58 : Float(1!, 48!, 300) = aten::slice[dim=0, start=13, end=14, step=1](%19), scope: RNN_ENCODER\n  %57 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=3900](%19), scope: RNN_ENCODER\n  %60 : Float(1!, 7!, 300) = aten::slice[dim=1, start=0, end=7, step=1](%58), scope: RNN_ENCODER\n  %59 : Float(1!, 7!, 300) = aten::as_strided[size=[1, 7, 300], stride=[300, 4500, 1], storage_offset=3900](%58), scope: RNN_ENCODER\n  %61 : Float(1, 7, 300) = aten::clone(%60), scope: RNN_ENCODER\n  %62 : Float(7, 300) = aten::view[size=[-1, 300]](%61), scope: RNN_ENCODER\n  %64 : Float(1!, 48!, 300) = aten::slice[dim=0, start=14, end=15, step=1](%19), scope: RNN_ENCODER\n  %63 : Float(1!, 48!, 300) = aten::as_strided[size=[1, 48, 300], stride=[300, 4500, 1], storage_offset=4200](%19), scope: RNN_ENCODER\n  %66 : Float(1!, 4!, 300) = aten::slice[dim=1, start=0, end=4, step=1](%64), scope: RNN_ENCODER\n  %65 : Float(1!, 4!, 300) = aten::as_strided[size=[1, 4, 300], stride=[300, 4500, 1], storage_offset=4200](%64), scope: RNN_ENCODER\n  %67 : Float(1, 4, 300) = aten::clone(%66), scope: RNN_ENCODER\n  %68 : Float(4, 300) = aten::view[size=[-1, 300]](%67), scope: RNN_ENCODER\n  %69 : Float(502, 300) = aten::cat[dim=0](%26, %32, %38, %44, %50, %56, %62, %68), scope: RNN_ENCODER\n  return ();\n}\n, <function _symbolic_pack_padded_sequence.<locals>.pack_padded_sequence_trace_wrapper at 0x1c28bcb2f0>, [16 defined in (%16 : Float(48, 15, 300), %17 : Handle = ^Dropout(0.5, False, False)(%13), scope: RNN_ENCODER/Dropout[drop]\n), [15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0]], 2, <function _symbolic_pack_padded_sequence.<locals>._onnx_symbolic_pack_padded_sequence at 0x1c37cfd950>"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "torch_out = torch.onnx.export(text_encoder,                 # model being run\n",
    "                               (captions_fake_input, cap_lens, hidden), # model input (or a tuple for multiple inputs)\n",
    "                               \"kol.onnx\",      # where to save the model (can be a file or file-like object)\n",
    "                               export_params=True)           # store the trained parameter weights inside the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
